<?xml version="1.0" encoding="UTF-8"?>
<launch>
    <!-- Launch arguments -->
    <arg name="bag_file" default="closed.bag" doc="Bag file to play"/>
    <arg name="bag_path" default="/rosbag" doc="Path to bag file"/>
    <arg name="loop" default="true" doc="Loop playback"/>
    <arg name="rate" default="1.0" doc="Playback rate multiplier"/>
    <arg name="delay" default="5" doc="Startup delay in seconds"/>
    <arg name="use_sim_time" default="true" doc="Use simulation time"/>
    <arg name="search_text" default="[a door]" doc="Text prompt for SAM"/>
    <arg name="image_topic" default="/camera/color/image_raw" doc="RGB image topic"/>
    <arg name="owl_image_encoder" default="/opt/nanoowl/data/owl_image_encoder_patch32.engine" doc="Path to OWL image encoder model"/>
    <arg name="sam_image_encoder" default="/opt/nanosam/data/resnet18_image_encoder.engine" doc="Path to SAM image encoder model"/>
    <arg name="sam_mask_decoder" default="/opt/nanosam/data/mobile_sam_mask_decoder.engine" doc="Path to SAM mask decoder model"/>
    <arg name="point_cloud_topic" default="/camera/depth_registered/points" doc="Point cloud topic"/>
    <arg name="camera_frame" default="camera_link" doc="Camera frame ID"/>
    <arg name="start_rviz" default="true" doc="Start RViz"/>
    <arg name="rviz_config" default="$(find sam_fp)/rviz/default.rviz" doc="RViz config file"/>
    <arg name="hf_endpoint" default="https://hf-mirror.com" doc="Hugging Face endpoint URL"/>
    <arg name="tensorrt_path" default="" doc="TensorRT library path"/>

    <!-- Environment variables -->
    <env name="HF_ENDPOINT" value="$(arg hf_endpoint)"/>
    <env name="LD_LIBRARY_PATH" 
         value="$(env LD_LIBRARY_PATH):$(arg tensorrt_path)" 
         if="$(eval len(arg('tensorrt_path')) > 0)"/>

    <!-- Set use_sim_time parameter -->
    <param name="/use_sim_time" value="$(arg use_sim_time)"/>

    <!-- Set enable_metrics parameter -->
    <param name="/enable_metrics" value="false"/>

    <!-- Rosbag play node -->
    <node pkg="rosbag" type="play" name="player" output="screen"
          launch-prefix="bash -c 'sleep $(arg delay); $0 $@'"
          args="$(eval arg('bag_path') + '/' + arg('bag_file') + ' ' + (arg('loop') and '-l' or '') + ' --clock -r ' + str(arg('rate')))">
    </node>

    <!-- SAM node -->
    <node name="sam_node" pkg="sam_fp" type="samros.py" output="screen">
        <param name="search_text" value="$(arg search_text)"/>
        <param name="image_topic" value="$(arg image_topic)"/>
        <param name="owl_image_encoder" value="$(arg owl_image_encoder)"/>
        <param name="sam_image_encoder" value="$(arg sam_image_encoder)"/>
        <param name="sam_mask_decoder" value="$(arg sam_mask_decoder)"/>
    </node>

    <!-- Point cloud processing node -->
    <node name="pcd_processing_node" pkg="sam_fp" type="pcd_processing_node" output="screen">
        <param name="pointcloud_topic" value="$(arg point_cloud_topic)"/>
        <param name="base_frame" value="$(arg camera_frame)"/>
    </node>

    <!-- Wall detection node -->
    <node name="wall_detection_node" pkg="sam_fp" type="wall_detection_node" output="screen">
        <param name="pointcloud_topic" value="/background_cloud"/>
        <param name="base_frame" value="$(arg camera_frame)"/>
    </node>

    <!-- RViz -->
    <node if="$(arg start_rviz)" 
          name="rviz" pkg="rviz" type="rviz" 
          args="-d $(arg rviz_config)" 
          output="screen"/>

    <!-- TF tree configuration if needed -->
    <!-- <node pkg="tf" type="static_transform_publisher" name="camera_broadcaster" 
          args="0 0 0 0 0 0 map $(arg camera_frame) 100" /> -->
</launch> 